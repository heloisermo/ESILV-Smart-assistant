# ESILV Smart Assistant

ğŸ¤– Assistant intelligent pour l'ESILV utilisant le scraping web, la recherche vectorielle (RAG) et Google Vertex AI.

**ğŸŒ Site du projet :** [https://esilv-chatbot-970477989170.us-central1.run.app/](https://esilv-chatbot-970477989170.us-central1.run.app/)

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“– Table des matiÃ¨res

- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Installation et Configuration](#-installation-et-configuration-premiÃ¨re-fois)
- [CrÃ©er l'index initial](#-crÃ©er-lindex-initial-scraping--indexation)
- [Lancer l'application](#-lancer-lapplication)
- [Structure du projet](#-structure-du-projet)
- [Mise Ã  jour des donnÃ©es](#-mise-Ã -jour-des-donnÃ©es)
- [DÃ©ploiement sur GCP](#-dÃ©ploiement-sur-google-cloud-platform)
- [Tests](#-tests)
- [Configuration avancÃ©e](#ï¸-configuration-avancÃ©e)
- [RÃ©solution des problÃ¨mes](#-rÃ©solution-des-problÃ¨mes)
- [Contribution](#-contribution)

## âœ¨ FonctionnalitÃ©s

- ğŸ” **Scraping web intelligent** : Extraction automatique du contenu du site ESILV
- ğŸ§  **Recherche vectorielle (RAG)** : Recherche sÃ©mantique avec FAISS et embeddings multilingues
- ğŸ¤– **Multi-agents** : Orchestration intelligente entre agent RAG et agent de contact
- ğŸ’¬ **Interface conversationnelle** : Chat intuitif avec Streamlit
- ğŸ“ **Gestion des leads** : Collecte et export des demandes de contact
- ğŸ“„ **Upload de documents** : Indexation de PDF, DOCX, TXT
- ğŸ” **Interface admin** : Gestion complÃ¨te des donnÃ©es et rÃ©indexation
- â˜ï¸ **DÃ©ploiement GCP** : PrÃªt pour Cloud Run avec streaming optimisÃ©

## ğŸš€ Installation et Configuration (PremiÃ¨re fois)

### PrÃ©requis

- Python 3.9 ou supÃ©rieur
- Un compte Google Cloud Platform (GCP) avec Vertex AI activÃ©
- Les credentials GCP (fichier JSON de service account)

### 1. Cloner le projet

```bash
git clone <url-du-repo>
cd ESILV-Smart-assistant
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. Configuration de Google Vertex AI

#### a) CrÃ©er un projet GCP et activer Vertex AI

1. Aller sur [Google Cloud Console](https://console.cloud.google.com/)
2. CrÃ©er un nouveau projet ou sÃ©lectionner un projet existant
3. Activer l'API Vertex AI :
   - Aller dans "APIs & Services" > "Enable APIs and Services"
   - Rechercher "Vertex AI API" et l'activer

#### b) CrÃ©er un service account et tÃ©lÃ©charger les credentials

1. Aller dans "IAM & Admin" > "Service Accounts"
2. Cliquer sur "Create Service Account"
3. Donner un nom (ex: `esilv-smart-assistant`)
4. Attribuer les rÃ´les :
   - `Vertex AI User`
   - `Storage Object Viewer` (si besoin)
5. CrÃ©er une clÃ© JSON :
   - Cliquer sur le service account crÃ©Ã©
   - Onglet "Keys" > "Add Key" > "Create new key"
   - Choisir le format JSON
   - Le fichier JSON sera tÃ©lÃ©chargÃ© automatiquement
6. Placer le fichier JSON dans `Back/app/` (ex: `Back/app/esilv-smart-assistant-xxxxx.json`)

### 4. Configuration de l'environnement (.env)

CrÃ©er un fichier `.env` Ã  la racine du projet avec le contenu suivant :

```env
# Configuration du scraping
SCRAPING_URL=https://www.esilv.fr/

# Configuration de la base de donnÃ©es vectorielle
CHROMA_DB_PATH=./data/chroma_db

# Configuration du RAG
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

SYSTEM_PROMPT="Tu es un assistant pour l'ecole d'ingenieurs ESILV. Reponds aux questions en utilisant le contexte fourni. Si l'information n'est pas presente dans le contexte mais que tu penses qu'elle pourrait se trouver sur le site ESILV, suggere a l'utilisateur de consulter directement le site web https://www.esilv.fr ou indique-lui les pages pertinentes a visiter. Reponds toujours en francais et de maniere claire et concise."

# Vertex AI Configuration (SDK)
GOOGLE_APPLICATION_CREDENTIALS=C:\chemin\absolu\vers\votre\fichier.json
VERTEX_MODEL=gemini-2.0-flash-exp
VERTEX_PROJECT=votre-project-id-gcp
VERTEX_LOCATION=us-central1

# Admin Panel Authentication
ADMIN_PASSWORD=admin2025
```

**âš ï¸ Important :** 
- Remplacer `GOOGLE_APPLICATION_CREDENTIALS` par le chemin ABSOLU vers votre fichier JSON de credentials
- Remplacer `VERTEX_PROJECT` par votre Project ID GCP
- Le fichier `.env` est ignorÃ© par git pour la sÃ©curitÃ©

### 5. CrÃ©er l'index initial (scraping + indexation)

Pour initialiser la base de connaissances du chatbot, vous devez d'abord scraper le site web puis indexer les donnÃ©es. Il existe deux mÃ©thodes :

#### MÃ©thode 1 : Pipeline complet automatique (RecommandÃ© pour dÃ©buter)

```bash
python Back/app/rag/main.py
```

Cette commande va automatiquement :
1. Scraper le site ESILV (20 pages par dÃ©faut)
2. Indexer les documents scrapÃ©s
3. Effectuer un test de recherche

Vous pouvez ajuster les paramÃ¨tres dans le fichier `Back/app/rag/main.py` :
- `max_pages` : nombre de pages Ã  scraper
- `max_depth` : profondeur de navigation

#### MÃ©thode 2 : Ã‰tapes manuelles (Pour plus de contrÃ´le)

**a) Scraper le site web**

```bash
python Back/app/rag/scraper.py
```

Cette commande va :
- Scraper jusqu'Ã  500 pages du site ESILV
- Extraire le contenu principal de chaque page
- Sauvegarder les donnÃ©es dans `data/scraped_data.json`
- CrÃ©er une sauvegarde dans `data/archive_YYYYMMDD_HHMMSS/`
- Prendre environ 5-10 minutes selon la vitesse de connexion

**b) Indexer les donnÃ©es scrapÃ©es**

```bash
python Back/app/rag/indexer.py
```

Cette commande va :
- Charger les donnÃ©es de `data/scraped_data.json`
- DÃ©couper le contenu en chunks optimisÃ©s (1000 caractÃ¨res avec 100 de chevauchement)
- CrÃ©er les embeddings vectoriels avec le modÃ¨le `paraphrase-multilingual-MiniLM-L12-v2`
- GÃ©nÃ©rer l'index FAISS dans `data/faiss_index.bin`
- Sauvegarder le mapping dans `data/faiss_mapping.json`
- Prendre environ 2-5 minutes selon la quantitÃ© de donnÃ©es

**Note importante :** 
- Les scripts dans `Back/app/rag/` sont utilisÃ©s pour l'indexation **initiale** Ã  partir du scraping web
- Le module `admin_indexer.py` est utilisÃ© par l'interface Streamlit pour la **rÃ©indexation** et la gestion des documents uploadÃ©s
- Les donnÃ©es gÃ©nÃ©rÃ©es sont sauvegardÃ©es localement et ne sont pas versionnÃ©es dans git

### 6. Lancer l'application

#### Interface utilisateur (Streamlit)

```bash
cd Front
streamlit run streamlit_app.py
```

L'application sera accessible sur `http://localhost:8501`

## ğŸ“ Structure du projet

```
ESILV-Smart-assistant/
â”œâ”€â”€ .env                          # Configuration (Ã  crÃ©er - ignorÃ© par git)
â”œâ”€â”€ config.py                     # Gestion centralisÃ©e des chemins
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data/                         # DonnÃ©es gÃ©nÃ©rÃ©es (ignorÃ© par git)
â”‚   â”œâ”€â”€ scraped_data.json        # DonnÃ©es scrapÃ©es
â”‚   â”œâ”€â”€ faiss_index.bin          # Index vectoriel FAISS
â”‚   â”œâ”€â”€ faiss_mapping.json       # Mapping des chunks
â”‚   â”œâ”€â”€ processed_documents.json # MÃ©tadonnÃ©es des documents
â”‚   â”œâ”€â”€ archive_*/               # Sauvegardes automatiques
â”‚   â”œâ”€â”€ leads/                   # DonnÃ©es des leads
â”‚   â””â”€â”€ uploads/                 # Documents uploadÃ©s
â”‚
â”œâ”€â”€ Back/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ esilv-smart-assistant-xxxxx.json  # Credentials GCP (Ã  placer - ignorÃ© par git)
â”‚       â”œâ”€â”€ admin_indexer.py                  # Indexation pour l'interface admin (rÃ©indexation)
â”‚       â”œâ”€â”€ document_manager.py               # Gestion des documents uploadÃ©s
â”‚       â”œâ”€â”€ leads_manager.py                  # Gestion des leads
â”‚       â”‚
â”‚       â”œâ”€â”€ agents/                           # Agents conversationnels
â”‚       â”‚   â”œâ”€â”€ orchestrator.py              # Orchestrateur principal
â”‚       â”‚   â”œâ”€â”€ rag_agent.py                 # Agent RAG
â”‚       â”‚   â”œâ”€â”€ contact_agent.py             # Agent de contact
â”‚       â”‚   â””â”€â”€ base_agent.py                # Classe de base
â”‚       â”‚
â”‚       â””â”€â”€ rag/                             # SystÃ¨me RAG (indexation initiale)
â”‚           â”œâ”€â”€ main.py                      # Pipeline complet scraping + indexation
â”‚           â”œâ”€â”€ scraper.py                   # Script de scraping web
â”‚           â”œâ”€â”€ indexer.py                   # Script d'indexation initiale
â”‚           â”œâ”€â”€ chunker.py                   # DÃ©coupage de texte
â”‚           â””â”€â”€ rag.py                       # Recherche vectorielle (utilisÃ© par le chatbot)
â”‚
â”œâ”€â”€ Front/
â”‚   â”œâ”€â”€ streamlit_app.py         # Interface utilisateur
â”‚   â”œâ”€â”€ Dockerfile               # Configuration Docker pour dÃ©ploiement
â”‚   â””â”€â”€ assets/                  # Ressources visuelles
â”‚
â””â”€â”€ admin_pages/                 # Pages d'administration
    â”œâ”€â”€ auth.py                  # Authentification admin
    â”œâ”€â”€ document_management.py   # Gestion des documents
    â””â”€â”€ leads_management.py      # Gestion des leads
```

## ğŸ”„ Mise Ã  jour des donnÃ©es

### Re-scraper et re-indexer

Pour mettre Ã  jour les donnÃ©es du site ESILV, vous pouvez :

#### Via le pipeline complet
```bash
python Back/app/rag/main.py
```

#### Via les Ã©tapes manuelles
```bash
# 1. Re-scraper le site
python Back/app/rag/scraper.py

# 2. Re-indexer les donnÃ©es
python Back/app/rag/indexer.py
```

#### Via l'interface admin

L'application Streamlit inclut une interface d'administration accessible depuis le menu latÃ©ral qui permet de :
- Re-scraper et re-indexer directement depuis l'interface
- GÃ©rer les documents uploadÃ©s (PDF, DOCX, TXT)
- Consulter et exporter les leads/contacts

**Note :** L'interface admin utilise `admin_indexer.py` pour gÃ©rer l'indexation.

## ğŸš€ DÃ©ploiement sur Google Cloud Platform

### PrÃ©requis pour le dÃ©ploiement

1. **Compte GCP** avec facturation activÃ©e
2. **Google Cloud SDK** installÃ© ([Installation](https://cloud.google.com/sdk/docs/install))
3. **Docker** installÃ© (optionnel, pour tester localement)

### Configuration initiale GCP

```bash
# Se connecter Ã  GCP
gcloud auth login

# DÃ©finir votre projet
gcloud config set project VOTRE_PROJECT_ID

# Activer les APIs nÃ©cessaires
gcloud services enable run.googleapis.com
gcloud services enable cloudbuild.googleapis.com
gcloud services enable artifactregistry.googleapis.com
```

### DÃ©ploiement sur Cloud Run

#### Option 1 : DÃ©ploiement avec variables d'environnement

```bash
# Depuis le dossier racine du projet
cd ESILV-Smart-assistant

# Construire et dÃ©ployer
gcloud run deploy esilv-chatbot \
  --source ./Front \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --port 8501 \
  --memory 2Gi \
  --cpu 2 \
  --timeout 300 \
  --set-env-vars VERTEX_MODEL=gemini-2.0-flash-exp,VERTEX_PROJECT=votre-projet-gcp,VERTEX_LOCATION=us-central1
```

#### Option 2 : DÃ©ploiement avec fichier env.yaml

CrÃ©ez un fichier `env.yaml` Ã  la racine :

```yaml
VERTEX_MODEL: "gemini-2.0-flash-exp"
VERTEX_PROJECT: "votre-projet-gcp"
VERTEX_LOCATION: "us-central1"
ADMIN_PASSWORD: "votre-mot-de-passe-admin"
```

Puis dÃ©ployez :

```bash
gcloud run deploy esilv-chatbot \
  --source ./Front \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --env-vars-file env.yaml
```

#### Option 3 : Utilisation de Secret Manager (RecommandÃ© pour la production)

```bash
# 1. CrÃ©er les secrets
echo -n "votre-mot-de-passe-admin" | gcloud secrets create admin-password --data-file=-

# 2. Donner accÃ¨s Ã  Cloud Run
PROJECT_NUMBER=$(gcloud projects describe VOTRE_PROJECT_ID --format="value(projectNumber)")
gcloud secrets add-iam-policy-binding admin-password \
  --member=serviceAccount:${PROJECT_NUMBER}-compute@developer.gserviceaccount.com \
  --role=roles/secretmanager.secretAccessor

# 3. DÃ©ployer avec les secrets
gcloud run deploy esilv-chatbot \
  --source ./Front \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --set-env-vars VERTEX_MODEL=gemini-2.0-flash-exp,VERTEX_PROJECT=votre-projet-gcp \
  --set-secrets ADMIN_PASSWORD=admin-password:latest
```

### Test local avec Docker

```bash
# Construire l'image
cd Front
docker build -t esilv-chatbot .

# Lancer le conteneur
docker run -p 8501:8501 --env-file ../.env esilv-chatbot

# AccÃ©der Ã  http://localhost:8501
```

### Mise Ã  jour du dÃ©ploiement

```bash
# RedÃ©ployer avec la nouvelle version
gcloud run deploy esilv-chatbot \
  --source ./Front \
  --platform managed \
  --region us-central1
```

### Logs et monitoring

```bash
# Voir les logs
gcloud run logs read esilv-chatbot --region us-central1

# Voir les logs en temps rÃ©el
gcloud run logs tail esilv-chatbot --region us-central1

# Voir les builds en cours
gcloud builds list --filter="status=WORKING" --limit=5
```

### Configuration d'un domaine personnalisÃ©

1. Aller dans la console Cloud Run
2. SÃ©lectionner votre service `esilv-chatbot`
3. Cliquer sur "Manage custom domains"
4. Suivre les instructions pour mapper votre domaine

### Estimation des coÃ»ts Cloud Run

Cloud Run facture selon l'utilisation :
- **Gratuit** : 2 millions de requÃªtes/mois
- **CPU** : ~$0.00002400 par vCPU-seconde
- **MÃ©moire** : ~$0.00000250 par GiB-seconde
- **RequÃªtes** : $0.40 par million de requÃªtes

**Estimation** : ~10-50â‚¬/mois pour un usage modÃ©rÃ© (quelques centaines d'utilisateurs)

### Checklist de dÃ©ploiement

- [ ] Variables d'environnement configurÃ©es
- [ ] Secrets crÃ©Ã©s dans Secret Manager (pour production)
- [ ] APIs activÃ©es (Cloud Run, Cloud Build, Artifact Registry)
- [ ] Facturation activÃ©e sur le projet GCP
- [ ] Fichiers .env et credentials non commitÃ©s (vÃ©rifier .gitignore)
- [ ] Test en local rÃ©ussi
- [ ] DÃ©ploiement Cloud Run effectuÃ©
- [ ] URL testÃ©e et fonctionnelle
- [ ] Logs vÃ©rifiÃ©s (pas d'erreurs au dÃ©marrage)

## ğŸ§ª Tests

Pour tester le systÃ¨me RAG complet (scraping + indexation + recherche) :

```bash
python Back/app/rag/main.py
```

Cette commande effectue un test complet du pipeline et affiche des rÃ©sultats de recherche.

## âš™ï¸ Configuration avancÃ©e

### ModÃ¨les Vertex AI disponibles

Dans le fichier `.env`, vous pouvez changer le modÃ¨le utilisÃ© :
- `gemini-2.0-flash-exp` (par dÃ©faut, le plus rapide)
- `gemini-1.5-pro`
- `gemini-1.5-flash`

### ParamÃ¨tres de chunking

Dans le fichier `.env` :
- `CHUNK_SIZE` : Taille des chunks de texte (dÃ©faut: 1000)
- `CHUNK_OVERLAP` : Chevauchement entre chunks (dÃ©faut: 200)

### ModÃ¨le d'embeddings

Le modÃ¨le `paraphrase-multilingual-MiniLM-L12-v2` est utilisÃ© par dÃ©faut pour les embeddings.
Modifiable dans `Back/app/admin_indexer.py` (variable `MODEL_NAME`).

## ğŸ”’ SÃ©curitÃ©

**Fichiers sensibles ignorÃ©s par git :**
- `.env` : Variables d'environnement et mots de passe
- `Back/app/*.json` : Credentials GCP
- `data/` : Toutes les donnÃ©es gÃ©nÃ©rÃ©es
- `__pycache__/` : Fichiers Python compilÃ©s

**âš ï¸ Ne JAMAIS commiter :**
- Les credentials GCP (fichiers .json)
- Le fichier .env
- Les donnÃ©es scrapÃ©es ou indexÃ©es

## ğŸ› RÃ©solution des problÃ¨mes

### Erreur : "GOOGLE_APPLICATION_CREDENTIALS not found"

VÃ©rifier que :
1. Le chemin dans `.env` est correct et ABSOLU
2. Le fichier JSON existe bien Ã  cet emplacement
3. Les permissions de lecture sont correctes

### Erreur lors du scraping

VÃ©rifier :
1. La connexion internet
2. L'URL dans `.env` est accessible
3. Le site cible n'a pas changÃ© sa structure

### Erreur lors de l'indexation

VÃ©rifier :
1. Le fichier `data/scraped_data.json` existe
2. Il contient des donnÃ©es valides
3. Suffisamment d'espace disque disponible

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Consultez le fichier [CONTRIBUTING.md](CONTRIBUTING.md) pour les guidelines.

### Comment contribuer
1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Ajoute une fonctionnalitÃ© incroyable'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ‘¥ Auteurs

- **Ã‰quipe ESILV Smart Assistant** - DÃ©veloppement initial

## ğŸ™ Remerciements

- ESILV pour le contenu du site web
- Google Cloud Platform pour Vertex AI
- La communautÃ© open source pour les bibliothÃ¨ques utilisÃ©es

## ğŸ“ Support

Pour toute question ou problÃ¨me :
- Ouvrir une [issue](../../issues) sur GitHub
- Consulter la documentation
- Contacter l'Ã©quipe de dÃ©veloppement

---

**Fait avec â¤ï¸ pour l'ESILV**
