# ESILV Smart Assistant

Assistant intelligent pour l'ESILV utilisant le scraping web et la recherche vectorielle (RAG).

## Installation et premiÃ¨re utilisation

### 1. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 2. Configuration de l'environnement

CrÃ©er un fichier `.env` dans le dossier `Back/app/rag/` avec l'URL Ã  scraper :

```env
SCRAPING_URL=https://www.esilv.fr/
```

### 3. Scraper le site (premiÃ¨re fois)

```bash
cd Back/app/rag
python scraper.py
```

Cette commande va :
- Scraper jusqu Ã  100 pages du site
- Sauvegarder les donnÃ©es dans `data/scraped_data.json`
- Prendre environ 2-3 minutes

### 4. Indexer les donnÃ©es (premiÃ¨re fois)

```bash
python indexer.py
```

Cette commande va :
- CrÃ©er les embeddings vectoriels
- GÃ©nÃ©rer l index FAISS dans `data/faiss_index.bin`
- Sauvegarder le mapping dans `data/faiss_mapping.json`

## Structure des fichiers

```
ESILV-Smart-assistant/
â”œâ”€â”€ Back/
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ rag/
â”‚           â”œâ”€â”€ data/              # Dossier des donnÃ©es gÃ©nÃ©rÃ©es (ignorÃ© par git)
â”‚           â”‚   â”œâ”€â”€ scraped_data.json
â”‚           â”‚   â”œâ”€â”€ faiss_index.bin
â”‚           â”‚   â””â”€â”€ faiss_mapping.json
â”‚           â”œâ”€â”€ scraper.py         # Script de scraping
â”‚           â”œâ”€â”€ indexer.py         # Script d indexation
â”‚           â””â”€â”€ .env               # Configuration (Ã  crÃ©er)
â””â”€â”€ requirements.txt
```

## ğŸ§ª Tests

Pour tester le systÃ¨me complet :

```bash
python test_simple.py
```

## âš™ï¸ Configuration

- **SCRAPING_URL** : URL de base Ã  scraper (dans `.env`)
- **limit** : Nombre maximum de pages Ã  scraper (modifiable dans `scraper.py`)
- **ModÃ¨le d embeddings** : `all-MiniLM-L6-v2` (configurable dans `indexer.py`)
